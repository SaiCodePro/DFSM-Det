{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b4d8f1f",
      "metadata": {
        "id": "4b4d8f1f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import pickle as pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7178801b",
      "metadata": {
        "id": "7178801b"
      },
      "outputs": [],
      "source": [
        "class Simulation_o:\n",
        "    def __init__(self, QAM = 4,Num_cc = np.arange(0,10), Num_ii = 100,\n",
        "                 SNR_DB = np.arange(2,14,2), Nt = 16, Nr = 16, cesit = 0,\n",
        "                 cesir = 0,channel_error =.0):\n",
        "        self.Num_cc = Num_cc\n",
        "        self.Num_ii = Num_ii\n",
        "        self.SNR_DB = SNR_DB\n",
        "        self.N_t = Nt\n",
        "        self.N_r = Nr\n",
        "        self.QAM = QAM\n",
        "        self.cesit = cesit\n",
        "        self.cesir = cesir\n",
        "        self.channel_error = channel_error\n",
        "\n",
        "\n",
        "    def data_generation(self):\n",
        "        m=1\n",
        "        M=[]\n",
        "        for i in range(int(np.sqrt(self.QAM)/2)):\n",
        "            M.append(m)\n",
        "            M.append(-m)\n",
        "            m+=2\n",
        "\n",
        "        s = {}\n",
        "        H = {}\n",
        "        r = {}\n",
        "        var = {}\n",
        "\n",
        "        d =np.abs(M[0]-M[1])\n",
        "        E = (self.QAM-1)*((d*d)/2)/3\n",
        "\n",
        "        for cc in self.Num_cc:\n",
        "            Z=1*self.N_r # RIS dimention element\n",
        "            np.random.seed(cc)\n",
        "            h = np.zeros((self.Num_ii,self.N_r,self.N_t)) + np.sqrt(0.5/self.N_r)*(np.random.randn(self.N_r,self.N_t)+np.random.randn(self.N_r,self.N_t)*1j)\n",
        "\n",
        "\n",
        "            ####################  RIS ######################\n",
        "            h1 = np.zeros((self.Num_ii,self.N_r,Z)) + np.sqrt(0.5/self.N_r)*(np.random.randn(self.N_r,Z)+np.random.randn(self.N_r,Z)*1j)\n",
        "            h2 = np.zeros((self.Num_ii,Z,self.N_t)) + np.sqrt(0.5/self.N_r)*(np.random.randn(Z,self.N_t)+np.random.randn(Z,self.N_t)*1j)\n",
        "\n",
        "            alfa = np.random.rand()\n",
        "            teta_deg = np.random.rand(Z) * 180\n",
        "            teta_gra = np.deg2rad(teta_deg)\n",
        "            Teta = np.exp(1j * teta_gra)\n",
        "            Phi = np.diag(Teta)\n",
        "\n",
        "            hh = h1@(alfa*Phi)@h2\n",
        "            h=h+hh\n",
        "            # print(Phi)\n",
        "            ####################  RIS ######################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            ####################  Channel estimation error ######################\n",
        "            h_e = np.sqrt(0.5/self.N_r)*((np.random.randn(self.N_r,self.N_t)+np.random.randn(self.N_r,self.N_t)*1j))*np.sqrt(self.channel_error/2 )\n",
        "            ####################  Channel estimation error ######################\n",
        "\n",
        "\n",
        "\n",
        "            ####################  corolation ######################\n",
        "\n",
        "            Rr = np.zeros((self.N_r, self.N_r))+0*1j\n",
        "            Rt = np.zeros((self.N_t, self.N_t))+0*1j\n",
        "\n",
        "            angle_deg = np.random.rand() * 90\n",
        "            angle_rad = np.deg2rad(angle_deg)\n",
        "            exponential_complex = np.exp(1j * angle_rad)\n",
        "\n",
        "            rr = (self.cesir* exponential_complex) ** np.arange(self.N_r)\n",
        "            tt = (self.cesit * exponential_complex) ** np.arange(self.N_t)\n",
        "\n",
        "            for nn in range(self.N_t):\n",
        "                Rt[nn, nn:self.N_t] = tt[:self.N_t-nn]\n",
        "\n",
        "            for na in range(self.N_r):\n",
        "                Rr[na, na:self.N_r] = rr[:self.N_r-na]\n",
        "\n",
        "            Rt = Rt + np.conj(Rt.T) - np.eye(self.N_t)\n",
        "            Rr = Rr + np.conj(Rr.T) - np.eye(self.N_r)\n",
        "\n",
        "            ####################  corolation ######################\n",
        "\n",
        "            h = Rr@h@Rt\n",
        "            for snr in self.SNR_DB:\n",
        "                X = np.random.choice(M,(self.Num_ii,self.N_t,1))+np.random.choice(M,(self.Num_ii,self.N_t,1))*1j\n",
        "                x = X/np.sqrt(E)\n",
        "                vv = np.sqrt(0.5/(10** (snr/10))) * (np.random.randn(self.Num_ii,self.N_r,1)+np.random.randn(self.Num_ii,self.N_r,1)*1j)\n",
        "\n",
        "                y = h@x+vv\n",
        "\n",
        "                if cc == self.Num_cc[0]:\n",
        "                    var[snr] = vv\n",
        "                    s[snr]=x\n",
        "                    H[snr]=h+h_e\n",
        "                    r[snr]=y\n",
        "                else:\n",
        "                    var[snr]=np.concatenate((var[snr],vv),0)\n",
        "                    s[snr] = np.concatenate((s[snr],x),0)\n",
        "                    H[snr] = np.concatenate((H[snr],h+h_e),0)\n",
        "                    r[snr] = np.concatenate((r[snr],y),0)\n",
        "\n",
        "        return s, H, r, var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "742fc972",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "742fc972",
        "outputId": "a3ec2e16-4e2d-40fb-c54c-198fc63e31b1"
      },
      "outputs": [],
      "source": [
        "Num_cc = np.arange(0,100)\n",
        "Num_ii = 100\n",
        "SNR_DB = np.arange(10,24,2)\n",
        "Nt = 8\n",
        "Nr = 16\n",
        "QAM = 16\n",
        "cesit = .0\n",
        "cesir = .0\n",
        "channel_error_var=.0\n",
        "\n",
        "data = Simulation_o(QAM = QAM,Num_cc = Num_cc, Num_ii = Num_ii,\n",
        "                 SNR_DB = SNR_DB, Nt = Nt, Nr = Nr, cesit=cesit, cesir=cesir,channel_error =channel_error_var)\n",
        "s, H, r, n = data.data_generation()\n",
        "\n",
        "\n",
        "E = (QAM-1)*((2*2)/2)/3\n",
        "E"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "596c9f67",
      "metadata": {
        "id": "596c9f67"
      },
      "source": [
        "# Convert complex Data to real value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80e034ab",
      "metadata": {
        "id": "80e034ab"
      },
      "outputs": [],
      "source": [
        "for snr in SNR_DB:\n",
        "    sreal = np.real(s[snr])\n",
        "    simag = np.imag(s[snr])\n",
        "    s_real = np.concatenate((sreal,simag),1)\n",
        "\n",
        "    rreal = np.real(r[snr])\n",
        "    rimag = np.imag(r[snr])\n",
        "    r_real = np.concatenate((rreal,rimag),1)\n",
        "\n",
        "    hreal = np.real(H[snr])\n",
        "    himag = np.imag(H[snr])\n",
        "    hup = np.concatenate((hreal,-himag),2)\n",
        "    hdown = np.concatenate((himag,hreal),2)\n",
        "    h_real = np.concatenate((hup,hdown),1)\n",
        "\n",
        "    nreal = np.real(n[snr])\n",
        "    nimag = np.imag(n[snr])\n",
        "    n_real = np.concatenate((nreal,nimag),1)\n",
        "\n",
        "    if snr == SNR_DB[0]:\n",
        "\n",
        "        s_ = s_real\n",
        "        H_ = h_real\n",
        "        r_ = r_real\n",
        "        noise = n_real\n",
        "\n",
        "    else:\n",
        "\n",
        "        s_ = np.concatenate((s_ , s_real),0)\n",
        "        H_ = np.concatenate((H_ , h_real),0)\n",
        "        r_ = np.concatenate((r_ , r_real),0)\n",
        "        noise = np.concatenate((noise , n_real),0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53c27a80",
      "metadata": {
        "id": "53c27a80"
      },
      "source": [
        "‚Äç# Make MMSE matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb26a595",
      "metadata": {
        "id": "eb26a595"
      },
      "outputs": [],
      "source": [
        "sigmaI = (np.var(noise,1,keepdims=True)*np.eye(s_.shape[1]))\n",
        "\n",
        "A = (np.transpose(H_,(0,2,1)) @ H_+sigmaI)\n",
        "b = np.transpose(H_,(0,2,1)) @ r_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1caa449b",
      "metadata": {
        "id": "1caa449b"
      },
      "outputs": [],
      "source": [
        "L = np.tril(A)\n",
        "U = np.triu(A)\n",
        "D = -(A-U-L)\n",
        "M_inv = np.linalg.inv(D) # In verse of diagonal value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8784ad4b",
      "metadata": {
        "id": "8784ad4b"
      },
      "outputs": [],
      "source": [
        "norm_A = np.mean(np.linalg.norm(A,ord=2,axis=(1,2))) # Avrage norm of MMSE matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b45f6c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b45f6c3",
        "outputId": "1d0caabb-4082-4eea-c9ae-ca81a7c0f82b"
      },
      "outputs": [],
      "source": [
        "norm_A"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1974edf",
      "metadata": {
        "id": "d1974edf"
      },
      "source": [
        "# Seperate Testing and Training Dtata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37718167",
      "metadata": {
        "id": "37718167"
      },
      "outputs": [],
      "source": [
        "tr = np.arange(0,s_.shape[0],2)\n",
        "te = np.arange(1,s_.shape[0],2)\n",
        "\n",
        "s_tr = s_[tr]\n",
        "s_te = s_[te]\n",
        "\n",
        "H_tr = H_[tr]\n",
        "H_te = H_[te]\n",
        "\n",
        "A_tr = A[tr]\n",
        "A_te = A[te]\n",
        "\n",
        "b_tr = b[tr]\n",
        "b_te = b[te]\n",
        "\n",
        "M_i_tr = M_inv[tr]\n",
        "M_i_te = M_inv[te]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "870659f5",
      "metadata": {
        "id": "870659f5"
      },
      "outputs": [],
      "source": [
        "# EAch layer Architecture\n",
        "class Custom_layer(keras.layers.Layer):\n",
        "    def __init__(self , act):\n",
        "        super(Custom_layer, self).__init__()\n",
        "\n",
        "        self.act = act # Activation Function\n",
        "        self.W1 = self.add_weight(initializer=\"normal\", shape=(2*Nt,1),dtype=\"float32\", trainable=True, name = 'W1_')# Gradient weight\n",
        "        self.beta = self.add_weight(initializer=\"normal\", shape=(1,1),dtype=\"float32\", trainable=True, name = 'beta_')# First Momentum parameter\n",
        "        self.xi = self.add_weight(initializer=\"normal\", shape=(1,1),dtype=\"float32\", trainable=True, name = 'xi_') #Second  Momentum parameter\n",
        "\n",
        "\n",
        "\n",
        "    def call(self, inputs): # calling function for feeding forward\n",
        "        x, A, b, x_p, x_pp, M_i = inputs[0], inputs[1], inputs[2], inputs[3], inputs[4], inputs[5] # Import data from pervius layer\n",
        "\n",
        "\n",
        "\n",
        "        X = x + self.W1*M_i@(A@x-b)+self.beta*(x-x_p)+self.xi*(x-2*x_p+x_pp) # Operations of each layer\n",
        "\n",
        "        return self.act(X)\n",
        "\n",
        "# merge all layer\n",
        "class Model_train(keras.Model):\n",
        "    def __init__(self, model):\n",
        "        super(Model_train, self).__init__()\n",
        "\n",
        "        self.model = model # List of all layer\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, A, b, M_i= inputs[0], inputs[1], inputs[2], inputs[3]\n",
        "        List = []\n",
        "\n",
        "        X_p= x # output signal of 2 pervius layer\n",
        "        X_pp=x # output signal of 3 pervius layer\n",
        "        for i in range(len(self.model)):\n",
        "\n",
        "\n",
        "            x_p=x\n",
        "\n",
        "            x = self.model[i]([x, A, b,  X_p, X_pp,M_i]) # Feeding forward the considered layers\n",
        "\n",
        "            X_pp=X_p\n",
        "            X_p = x_p\n",
        "            List.append(x)\n",
        "\n",
        "\n",
        "        S = tf.concat(List,2)\n",
        "\n",
        "        return S,x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfb7b22b",
      "metadata": {
        "id": "dfb7b22b"
      },
      "outputs": [],
      "source": [
        "# making layer and set true value for loss function\n",
        "\n",
        "def built_net(layer,s,Nt,act):\n",
        "    model_list =[]\n",
        "    S_list = []\n",
        "    for i in range(layer):\n",
        "        S_list.append(s)\n",
        "        model_list.append(Custom_layer(act))\n",
        "\n",
        "    return np.concatenate(S_list,2), model_list\n",
        "\n",
        "\n",
        "# Activation function\n",
        "\n",
        "def activation(x):\n",
        "    x=np.sqrt(E)*x\n",
        "    sig =1.5\n",
        "    return (tf.tanh(sig*x)+tf.tanh(sig*x-2*sig)+tf.tanh(sig*x+2*sig))/np.sqrt(E)\n",
        "\n",
        "# Loss function\n",
        "def lf(outdv, Sd):\n",
        "    outd=outdv[0]\n",
        "    layer_ = Sd.shape[2]\n",
        "    Sd = tf.constant(Sd,dtype=tf.float32)\n",
        "\n",
        "    W = []\n",
        "    Alpha = []\n",
        "    Beta = []\n",
        "    j=0\n",
        "    for i in range (layer):\n",
        "\n",
        "        W.append(Model.trainable_variables[j])\n",
        "        j=j+1\n",
        "        Beta.append(Model.trainable_variables[j])\n",
        "        j=j+1\n",
        "        Alpha.append(Model.trainable_variables[j])\n",
        "        j=j+1\n",
        "\n",
        "\n",
        "\n",
        "    lf1 = tf.reduce_sum(tf.abs(1-norm_A*tf.concat(W,1)-tf.concat(Beta,1)-tf.concat(Alpha,1))+\n",
        "        tf.abs(tf.concat(Beta,1)+2*tf.concat(Alpha,1))+\n",
        "        tf.abs(tf.concat(Alpha,1))-1)\n",
        "\n",
        "    lf =   tf.norm(outd-Sd,ord=2,axis=1)**2\n",
        "\n",
        "\n",
        "    return tf.math.reduce_sum(lf*np.log(np.arange(2,layer_+2)))+0.001*lf1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "301377e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "301377e7",
        "outputId": "5703ae26-1b58-4a41-9575-1b7ae014d56f"
      },
      "outputs": [],
      "source": [
        "\n",
        "len(SNR_DB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a06ec9b",
      "metadata": {
        "id": "5a06ec9b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "y8krfJsTjtvD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "y8krfJsTjtvD",
        "outputId": "95b85315-dbcf-4d97-bece-08911438db5f"
      },
      "outputs": [],
      "source": [
        "x= np.linspace(-2,2,100)\n",
        "plt.plot(x,activation(x))\n",
        "activation(.5);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea28f4a2",
      "metadata": {
        "id": "ea28f4a2"
      },
      "outputs": [],
      "source": [
        "layer = 15 # number of layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b412e26",
      "metadata": {
        "id": "4b412e26"
      },
      "outputs": [],
      "source": [
        "S, model_list = built_net(layer,s_tr,Nt,activation) # Building layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5z7C3zWOAoOd",
      "metadata": {
        "id": "5z7C3zWOAoOd"
      },
      "outputs": [],
      "source": [
        "Model = Model_train(model_list) # Merge layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e88e1ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e88e1ee",
        "outputId": "11aa0fa1-bba3-408d-ca0d-1f58acadc179"
      },
      "outputs": [],
      "source": [
        "lf(Model([s_tr*0, A_tr, b_tr, M_i_tr]),S).numpy() # Tetsing loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38620d7d",
      "metadata": {
        "id": "38620d7d"
      },
      "outputs": [],
      "source": [
        "lr =.1\n",
        "opt = tf.keras.optimizers.Adam(lr) # call optimizer and set leraning rate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40185c12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "40185c12",
        "outputId": "c2905934-c877-41e6-faf6-a88f175ec313",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Training phase\n",
        "\n",
        "\n",
        "epochs = 1000\n",
        "for i in range(epochs):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = lf(Model([s_tr*0, A_tr, b_tr, M_i_tr]), S)\n",
        "\n",
        "    # Compute gradients\n",
        "    gradients = tape.gradient(loss_value, Model.trainable_variables)\n",
        "\n",
        "    # Apply gradients\n",
        "    opt.apply_gradients(zip(gradients, Model.trainable_variables))\n",
        "\n",
        "    # Print the loss for this epoch\n",
        "    print('ep:', i, 'Loss= ', loss_value.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NPPg3gvglUQ1",
      "metadata": {
        "id": "NPPg3gvglUQ1"
      },
      "source": [
        "# Testing the testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ac7a0be",
      "metadata": {
        "id": "7ac7a0be"
      },
      "outputs": [],
      "source": [
        "v= s_tr*0\n",
        "\n",
        "\n",
        "s_out = Model([s_te*0, A_te, b_te, M_i_te, v])[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d850d4c5",
      "metadata": {
        "id": "d850d4c5"
      },
      "outputs": [],
      "source": [
        "M = np.array([-3,-1,1,3])\n",
        "sym = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "S_Out = sym[np.expand_dims(np.argmin(np.abs(s_out*np.sqrt(E)-M),2),2)]\n",
        "S_True = sym[np.expand_dims(np.argmin(np.abs(s_te*np.sqrt(E)-M),2),2)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55a0be64",
      "metadata": {
        "id": "55a0be64"
      },
      "outputs": [],
      "source": [
        "er = S_Out != S_True\n",
        "l = int(er.shape[0]/len(SNR_DB))\n",
        "\n",
        "ber = []\n",
        "for i in range(len(SNR_DB)):\n",
        "    be = np.sum(er[i*l:(i+1)*l])/l/(4*Nt)\n",
        "\n",
        "    ber.append(be)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f157b93",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f157b93",
        "outputId": "9178d824-c5f6-40e9-8b28-aa36be622731"
      },
      "outputs": [],
      "source": [
        "ber\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f45c4f79",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "f45c4f79",
        "outputId": "cefaf59c-81d6-4722-a66b-93706e79d2af"
      },
      "outputs": [],
      "source": [
        "plt.semilogy(SNR_DB,ber)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2W5JOOtwicJO",
      "metadata": {
        "id": "2W5JOOtwicJO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
